{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "1DDSoxf-OhT4",
    "outputId": "629ad070-2d22-4b58-e69e-220a49df332a"
   },
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-40b6954cdd7b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatagenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'data/Train400'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-40b6954cdd7b>\u001b[0m in \u001b[0;36mdatagenerator\u001b[0;34m(data_dir, verbose)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' is done ^_^'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0mdiscard_n\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_size\u001b[0m  \u001b[0;31m# because of batch namalization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscard_n\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mexpand_dims\u001b[0;34m(a, axis)\u001b[0m\n\u001b[1;32m    595\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m     \u001b[0mout_ndim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 597\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnormalize_axis_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_ndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m     \u001b[0mshape_it\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36mnormalize_axis_tuple\u001b[0;34m(axis, ndim, argname, allow_duplicate)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/numeric.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;31m# Going via an iterator directly is slower than via list comprehension.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1358\u001b[0;31m     \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnormalize_axis_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1359\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_duplicate\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAxisError\u001b[0m: axis 3 is out of bounds for array of dimension 2"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "# =============================================================================\n",
    "#  @article{zhang2017beyond,\n",
    "#    title={Beyond a {Gaussian} denoiser: Residual learning of deep {CNN} for image denoising},\n",
    "#    author={Zhang, Kai and Zuo, Wangmeng and Chen, Yunjin and Meng, Deyu and Zhang, Lei},\n",
    "#    journal={IEEE Transactions on Image Processing},\n",
    "#    year={2017},\n",
    "#    volume={26}, \n",
    "#    number={7}, \n",
    "#    pages={3142-3155}, \n",
    "#  }\n",
    "# by Kai Zhang (08/2018)\n",
    "# cskaizhang@gmail.com\n",
    "# https://github.com/cszn\n",
    "# modified on the code from https://github.com/SaoYan/DnCNN-PyTorch\n",
    "# =============================================================================\n",
    "\n",
    "# no need to run this code separately\n",
    "\n",
    "\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "# from multiprocessing import Pool\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "\n",
    "patch_size, stride = 40, 10\n",
    "aug_times = 1\n",
    "scales = [1, 0.9, 0.8, 0.7]\n",
    "batch_size = 128\n",
    "\n",
    "\n",
    "class DenoisingDataset(Dataset):\n",
    "    \"\"\"Dataset wrapping tensors.\n",
    "    Arguments:\n",
    "        xs (Tensor): clean image patches\n",
    "        sigma: noise level, e.g., 25\n",
    "    \"\"\"\n",
    "    def __init__(self, xs, sigma):\n",
    "        super(DenoisingDataset, self).__init__()\n",
    "        self.xs = xs\n",
    "        self.sigma = sigma\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_x = self.xs[index]\n",
    "        noise = torch.randn(batch_x.size()).mul_(self.sigma/255.0)\n",
    "        batch_y = batch_x + noise\n",
    "        return batch_y, batch_x\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.xs.size(0)\n",
    "\n",
    "\n",
    "def show(x, title=None, cbar=False, figsize=None):\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(x, interpolation='nearest', cmap='gray')\n",
    "    if title:\n",
    "        plt.title(title)\n",
    "    if cbar:\n",
    "        plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def data_aug(img, mode=0):\n",
    "    # data augmentation\n",
    "    if mode == 0:\n",
    "        return img\n",
    "    elif mode == 1:\n",
    "        return np.flipud(img)\n",
    "    elif mode == 2:\n",
    "        return np.rot90(img)\n",
    "    elif mode == 3:\n",
    "        return np.flipud(np.rot90(img))\n",
    "    elif mode == 4:\n",
    "        return np.rot90(img, k=2)\n",
    "    elif mode == 5:\n",
    "        return np.flipud(np.rot90(img, k=2))\n",
    "    elif mode == 6:\n",
    "        return np.rot90(img, k=3)\n",
    "    elif mode == 7:\n",
    "        return np.flipud(np.rot90(img, k=3))\n",
    "\n",
    "\n",
    "def gen_patches(file_name):\n",
    "    # get multiscale patches from a single image\n",
    "    img = cv2.imread(file_name, 0)  # gray scale\n",
    "    h, w = img.shape\n",
    "    patches = []\n",
    "    \n",
    "    for s in scales:\n",
    "        h_scaled, w_scaled = int(h*s), int(w*s)\n",
    "        img_scaled = cv2.resize(img, (w_scaled, w_scaled), interpolation=cv2.INTER_CUBIC)\n",
    "        # extract patches\n",
    "        for i in range(0, h_scaled-patch_size+1, stride):\n",
    "            for j in range(0, w_scaled-patch_size+1, stride):\n",
    "                x = img_scaled[i:i+patch_size, j:j+patch_size]\n",
    "                for k in range(0, aug_times):\n",
    "                    x_aug = data_aug(x, mode=np.random.randint(0, 8))\n",
    "                    patches.append(x_aug)\n",
    "    \n",
    "    return patches\n",
    "\n",
    "\"\"\"\n",
    "def datagenerator_noise(data_dir='', verbose=False):\n",
    "    file_list = glob.glob(data_dir + '/*png')\n",
    "    data = []\n",
    "    \n",
    "    for i in range(len(file_list)):\n",
    "        patches = [cv2.imread(file_list[i], 0)] #gen_patches(file_list[i]) #[cv2.imread(x_Train_file_list[i], 1)]\n",
    "        for patch in patches:\n",
    "            data.append(patch)\n",
    "        if verbose:\n",
    "            print(str(i+1) + '/' + str(len(file_list)) + ' is done ^_^')\n",
    "    \n",
    "    data = np.array(data)\n",
    "    data = np.expand_dims(data, axis = 3)\n",
    "    discard_n = len(data)-len(data)//batch_size*batch_size  # because of batch namalization\n",
    "    data = np.delete(data, range(discard_n), axis=0)\n",
    "    \n",
    "    print('^_^-training data finished-^_^')\n",
    "    \n",
    "    return data\n",
    "\n",
    "def datagenerator_original(data_dir='', verbose=False):\n",
    "    file_list = glob.glob(data_dir + '/*jpg')\n",
    "    data = []\n",
    "    \n",
    "    for i in range(len(file_list)):\n",
    "        patches = [cv2.imread(file_list[i], 0)] #gen_patches(file_list[i]) #[cv2.imread(x_Train_file_list[i], 1)]\n",
    "        for patch in patches:\n",
    "            data.append(patch)\n",
    "        if verbose:\n",
    "            print(str(i+1) + '/' + str(len(file_list)) + ' is done ^_^')\n",
    "    \n",
    "    data = np.array(data)\n",
    "    data = np.expand_dims(data, axis = 3)\n",
    "    discard_n = len(data)-len(data)//batch_size*batch_size  # because of batch namalization\n",
    "    data = np.delete(data, range(discard_n), axis=0)\n",
    "    \n",
    "    print('^_^-training data finished-^_^')\n",
    "    \n",
    "    return data\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "def datagenerator(data_dir = 'Noise_image_Training(qp22)', verbose = False):\n",
    "    # generate clean patches from a dataset\n",
    "    file_list = glob.glob(data_dir+'/*.png')  # get name list of all .png files\n",
    "    # initrialize\n",
    "    data = []\n",
    "    # generate patches\n",
    "    for i in range(len(file_list)):\n",
    "        patches = gen_patches(file_list[i])\n",
    "        for patch in patches:    \n",
    "            data.append(patch)\n",
    "        if verbose:\n",
    "            print(str(i+1) + '/' + str(len(file_list)) + ' is done ^_^')\n",
    "    \n",
    "    data = np.array(data, dtype='uint8')\n",
    "    data = np.expand_dims(data, axis=3)\n",
    "    discard_n = len(data)-len(data)//batch_size*batch_size  # because of batch namalization\n",
    "    data = np.delete(data, range(discard_n), axis=0)\n",
    "    print('^_^-training data finished-^_^')\n",
    "    return data\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__': \n",
    "\n",
    "    data = datagenerator(data_dir='Noise_image_Training(qp22)')\n",
    "\n",
    "\n",
    "#    print('Shape of result = ' + str(res.shape))\n",
    "#    print('Saving data...')\n",
    "#    if not os.path.exists(save_dir):\n",
    "#            os.mkdir(save_dir)\n",
    "#    np.save(save_dir+'clean_patches.npy', res)\n",
    "#    print('Done.')      "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "data_generator",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
