{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9445c6a1",
   "metadata": {},
   "source": [
    "## Import Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d2c2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import re\n",
    "import os, glob, datetime, time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.modules.loss import _Loss\n",
    "import torch.nn.init as init\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "import easydict\n",
    "import cv2\n",
    "# from multiprocessing import Pool\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83c72fd",
   "metadata": {},
   "source": [
    "## Define Model Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f636bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"model\" : \"DnCNN\",\n",
    "    \"batch_size\" : 128,\n",
    "    \"train_data\" : 'Noise_image_Training(qp22)',\n",
    "    \"origin_data\" : 'Noise_image_Training(qp22)_original',\n",
    "    \"sigma\" : 25,\n",
    "    \"epoch\" : 10,\n",
    "    \"lr\" : 1e-3\n",
    "})\n",
    "\n",
    "batch_size = args.batch_size\n",
    "cuda = torch.cuda.is_available()\n",
    "n_epoch = args.epoch\n",
    "sigma = args.sigma\n",
    "\n",
    "save_dir = os.path.join('models', args.model+'_' + 'sigma' + str(sigma))\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.mkdir(save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d9a7b6",
   "metadata": {},
   "source": [
    "## Define Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6625300a",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size, stride = 40, 10\n",
    "aug_times = 1\n",
    "scales = [1, 0.9, 0.8, 0.7]\n",
    "\n",
    "class DenoisingDataset(Dataset):\n",
    "    def __init__(self, ys, xs):\n",
    "        super(DenoisingDataset, self).__init__()\n",
    "        self.ys = ys # compression Noisy image\n",
    "        self.xs = xs # original image\n",
    "        \n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_x = self.xs[index]\n",
    "        batch_y = self.ys[index]\n",
    "        return batch_y, batch_x\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.xs.size(0)\n",
    "\n",
    "def datagenerator(data_dir, img_type):\n",
    "    file_list = glob.glob(data_dir + '/*.' + img_type)\n",
    "    data = []\n",
    "    for i in range(len(file_list)):\n",
    "        img = cv2.imread(file_list[i], 0)\n",
    "        data.append(img)\n",
    "    data = np.array(data, dtype = 'uint8')\n",
    "    data = np.expand_dims(data, axis=3)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e5e907",
   "metadata": {},
   "source": [
    "## Define DnCNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b700d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DnCNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, depth=17, n_channels=64, image_channels=1, use_bnorm=True, kernel_size=3):\n",
    "        \n",
    "        super(DnCNN, self).__init__()\n",
    "        kernel_size = 3\n",
    "        padding = 1\n",
    "        self.depth = depth\n",
    "        \n",
    "        self.conv_relu_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=image_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=True),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.conv_bn_relu_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=n_channels, kernel_size=kernel_size, padding=padding, bias=False),\n",
    "            nn.BatchNorm2d(n_channels, eps=0.0001, momentum = 0.95),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        \n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=n_channels, out_channels=image_channels, kernel_size=kernel_size, padding=padding, bias=False)\n",
    "        )\n",
    "\n",
    "        #self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        y = x\n",
    "        \n",
    "        out = self.conv_relu_layers(x)\n",
    "        \n",
    "        for _ in range(self.depth - 2):\n",
    "            out = self.conv_bn_relu_layers(out)\n",
    "        \n",
    "        out = self.conv_layers(out)\n",
    "        \n",
    "        return y - out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b079867",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findLastCheckpoint(save_dir):\n",
    "    file_list = glob.glob(os.path.join(save_dir, 'model_*.pth'))\n",
    "    if file_list:\n",
    "        epochs_exist = []\n",
    "        for file_ in file_list:\n",
    "            result = re.findall(\".*model_(.*).pth.*\", file_)\n",
    "            epochs_exist.append(int(result[0]))\n",
    "        initial_epoch = max(epochs_exist)\n",
    "    else:\n",
    "        initial_epoch = 0\n",
    "    return initial_epoch\n",
    "\n",
    "\n",
    "def log(*args, **kwargs):\n",
    "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def1295a",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4c9572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    # model selection\n",
    "    print('===> Building model')\n",
    "    model = DnCNN()\n",
    "    \n",
    "    initial_epoch = findLastCheckpoint(save_dir=save_dir)  # load the last model in matconvnet style\n",
    "    \n",
    "    if initial_epoch > 0:\n",
    "        print('resuming by loading epoch %03d' % initial_epoch)\n",
    "        model = torch.load(os.path.join(save_dir, 'model_%03d.pth' % initial_epoch))\n",
    "    \n",
    "    model.train()\n",
    "    criterion = nn.MSELoss(reduction = 'sum')\n",
    "    \n",
    "    if cuda:\n",
    "        model = model.cuda()\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=args.lr)\n",
    "    scheduler = MultiStepLR(optimizer, milestones=[30, 60, 90], gamma=0.2)  # learning rates\n",
    "    \n",
    "    train_dataset = datagenerator(args.train_data, 'png')\n",
    "    train_dataset = train_dataset.astype('float32')/255.0\n",
    "    train_dataset = torch.from_numpy(train_dataset.transpose((0, 3, 1, 2)))\n",
    "    \n",
    "    train_target = datagenerator(args.origin_data, 'jpg')\n",
    "    train_target = train_target.astype('float32')/255.0\n",
    "    train_target = torch.from_numpy(train_target.transpose((0, 3, 1, 2)))\n",
    "    \n",
    "    Noisy_Dataset = DenoisingDataset(train_dataset, train_target)\n",
    "    DLoader = DataLoader(dataset = Noisy_Dataset, num_workers=4, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    for epoch in range(initial_epoch, n_epoch):\n",
    "\n",
    "        scheduler.step(epoch)  # step to the learning rate in this epcoh\n",
    "        epoch_loss = 0\n",
    "        start_time = time.time()\n",
    "\n",
    "        for n_count, batch_yx in enumerate(DLoader):\n",
    "                optimizer.zero_grad()\n",
    "                if cuda:\n",
    "                    batch_y, batch_x = batch_yx[0].cuda(), batch_yx[1].cuda()\n",
    "                denoising = model(batch_y)\n",
    "                copy_denoising = denoising.data.cpu().numpy()\n",
    "                loss = criterion(copy_denoising, batch_x)\n",
    "                epoch_loss += loss.item()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                if n_count % 10 == 0:\n",
    "                    print('%4d %4d / %4d loss = %2.4f' % (epoch+1, n_count, train_dataset.size(0)//batch_size, loss.item()/batch_size))\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        log('epoch = %4d , loss = %4.4f , time = %4.2f s' % (epoch+1, epoch_loss/n_count, elapsed_time))\n",
    "        np.savetxt('train_result.txt', np.hstack((epoch+1, epoch_loss/n_count, elapsed_time)), fmt='%2.4f')\n",
    "        torch.save(model, os.path.join(save_dir, 'model_%03d.pth' % (epoch+1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd92cb5",
   "metadata": {},
   "source": [
    "## Import Test moduel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60c6470",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import peak_signal_noise_ratio as compare_psnr\n",
    "from skimage.metrics import structural_similarity as compare_ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff13d5e6",
   "metadata": {},
   "source": [
    "## Define Model Test Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110c99cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_args():\n",
    "\n",
    "    args = easydict.EasyDict({\n",
    "    \"set_dir\" : 'Test_set',\n",
    "    \"set_names\" : ['Test_set(qp22)'],\n",
    "    \"sigma\" : 25,\n",
    "    \"model_dir\" : os.path.join('models', 'DnCNN_sigma25'),\n",
    "    \"model_name\" : 'model_010.pth',\n",
    "    \"result_dir\" : 'results',\n",
    "    \"save_result\" : 0\n",
    "    })\n",
    "    return args\n",
    "\n",
    "\n",
    "def log(*args, **kwargs):\n",
    "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"), *args, **kwargs)\n",
    "\n",
    "\n",
    "def save_result(result, path):\n",
    "    path = path if path.find('.') != -1 else path+'.png'\n",
    "    ext = os.path.splitext(path)[-1]\n",
    "    if ext in ('.txt', '.dlm'):\n",
    "        np.savetxt(path, result, fmt='%2.4f')\n",
    "    else:\n",
    "        imsave(path, np.clip(result, 0, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c1f606",
   "metadata": {},
   "source": [
    "## Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6830b851",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    args = parse_args()\n",
    "\n",
    "    if not os.path.exists(os.path.join(args.model_dir, args.model_name)):\n",
    "\n",
    "        model = torch.load(os.path.join(args.model_dir, 'model.pth'))\n",
    "        log('load trained model on Train400 dataset by kai')\n",
    "    else:\n",
    "        model = torch.load(os.path.join(args.model_dir, args.model_name))\n",
    "        log('load trained model')\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model.cuda()\n",
    "\n",
    "    if not os.path.exists(args.result_dir):\n",
    "        os.mkdir(args.result_dir)\n",
    "\n",
    "    for set_cur in args.set_names:\n",
    "\n",
    "        if not os.path.exists(os.path.join(args.result_dir, set_cur)):\n",
    "            os.mkdir(os.path.join(args.result_dir, set_cur))\n",
    "        psnrs = []\n",
    "        ssims = []\n",
    "\n",
    "        for im in os.listdir(os.path.join(args.set_dir, set_cur)):\n",
    "            if im.endswith(\".jpg\") or im.endswith(\".bmp\") or im.endswith(\".png\"):\n",
    "                \n",
    "                x = np.array(cv2.imread(os.path.join(args.set_dir, set_cur, im), 0), dtype=np.float32)/255.0\n",
    "                h, w = x.shape\n",
    "                x = cv2.resize(x, (h, h), interpolation=cv2.INTER_CUBIC)\n",
    "                np.random.seed(seed=0)  # for reproducibility\n",
    "                y = x + np.random.normal(0, args.sigma/255.0, x.shape)  # Add Gaussian noise without clipping\n",
    "                y = y.astype(np.float32)\n",
    "                y_ = torch.from_numpy(y).view(1, -1, y.shape[0], y.shape[1])\n",
    "\n",
    "                torch.cuda.synchronize()\n",
    "                start_time = time.time()\n",
    "                y_ = y_.cuda()\n",
    "                x_ = model(y_)  # inference\n",
    "                x_ = x_.view(y.shape[0], y.shape[1])\n",
    "                x_ = x_.cpu()\n",
    "                x_ = x_.detach().numpy().astype(np.float32)\n",
    "                torch.cuda.synchronize()\n",
    "                elapsed_time = time.time() - start_time\n",
    "                print('%10s : %10s : %2.4f second' % (set_cur, im, elapsed_time))\n",
    "\n",
    "                psnr_x_ = compare_psnr(x, x_, data_range = 2)\n",
    "                ssim_x_ = compare_ssim(x, x_)\n",
    "                if args.save_result:\n",
    "                    name, ext = os.path.splitext(im)\n",
    "                    show(np.hstack((y, x_)))  # show the image\n",
    "                    save_result(x_, path=os.path.join(args.result_dir, set_cur, name+'_dncnn'+ext))  # save the denoised image\n",
    "                psnrs.append(psnr_x_)\n",
    "                ssims.append(ssim_x_)\n",
    "        psnr_avg = np.mean(psnrs)\n",
    "        ssim_avg = np.mean(ssims)\n",
    "        psnrs.append(psnr_avg)\n",
    "        ssims.append(ssim_avg)\n",
    "        if args.save_result:\n",
    "            save_result(np.hstack((psnrs, ssims)), path=os.path.join(args.result_dir, set_cur, 'results.txt'))\n",
    "        log('Datset: {0:10s} \\n  PSNR = {1:2.2f}dB, SSIM = {2:1.4f}'.format(set_cur, psnr_avg, ssim_avg))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
